%% LaTeX-Beamer template for KIT design
%% by Erik Burger, Christian Hammer
%% title picture by Klaus Krogmann
%%
%% version 2.4
%%
%% mostly compatible to KIT corporate design v2.0
%% http://intranet.kit.edu/gestaltungsrichtlinien.php
%%
%% Problems, bugs and comments to
%% burger@kit.edu

%% Class options
%%   aspect ratio options: 
%%   -- 16:9 (default)
%%   -- 4:3
%%   language options: 
%%   -- en (default)
%%   -- de
%%   position of navigation bar:
%%   -- navbarinline (default): bottom of the white canvas
%%   -- navbarinfooter : more compressed variant inside the footer
%%   -- navbarside : side bar at the left of the white canvas
%%   -- navbaroff : none
%% example: \documentclass[16:9,de,navbarinfooter]{sdqbeamer}
\documentclass[16:9,en,navbarinfooter]{sdqbeamer}

%% \documentclass{sdqbeamer} 

%% TITLE PICTURE

% if a custom picture is to be used on the title page, copy it into the 'logos'
% directory, in the line below, replace 'myimage' with the 
% filename (without extension) and uncomment the following line
% (picture proportions: 63 : 20 for standard, 169 : 40 for wide
% *.eps format if you use latex+dvips+ps2pdf, 
% *.jpg/*.png/*.pdf if you use pdflatex)

% \titleimage{myimage}

%% GROUP LOGO 

% for a custom group logo, copy your file into the 'logos'
% directory, insert the filename in the line below and uncomment it

\grouplogo{irl-logo}

% (*.eps format if you use latex+dvips+ps2pdf,
% *.jpg/*.png/*.pdf if you use pdflatex)

%% GROUP NAME

% for groups other than SDQ, please insert in the line below and uncomment it
% \groupname{My group}

% the presentation starts here 

\author{Caspar Friedrich Maximilian Nagy}

%% Title (and possibly subtitle) of the thesis
\title{Solving Real-World Robot Manipulation Tasks with Deep Reinforcement Learning}
\subtitle{Box Pushing on a real Panda Robot}

% Bibliography 
\usepackage{dsfont}
%\usepackage{multimedia}
%\usepackage{media9}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{pgfplots}
% \pgfplotsset{compat=1.15}
 \usepgfplotslibrary{groupplots}
\usepackage{subcaption}
\usepackage{pdflscape}
\usepackage{diagbox}
\usepackage{multicol}
\DeclareUnicodeCharacter{2212}{âˆ’}
\usepgfplotslibrary{groupplots,dateplot}
\usetikzlibrary{patterns,shapes.arrows}
\pgfplotsset{compat=newest}
\usepackage[citestyle=authoryear,bibstyle=numeric,hyperref,backend=biber%,style=verbose
]{biblatex}
\addbibresource{presentation.bib}
\bibhang1em
\usepackage{listings}
\begin{document}

%title page
\KITtitleframe{}

%table of contents

\section{Motivation}
\begin{frame}{Motivation}
\begin{itemize}
    \item Motion Primitives (MPs)
   \begin{itemize}
       \item solve otherwise unsolveable Reinforcement Learning problems\dots in Simulation.
       \item have nice properties for real robots
       \item have not yet been used for real-life reinforcement learning
   \end{itemize}
   \item So many questions
   \begin{itemize}
           \item How to design a gym environment for the real world?
           \item How big is the sim2real gap? How do we cross it?
           \item Does replanning help?
           \item Is it better than traditional methods?
           \item Strengths/weaknesses of MPs? 
   \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Agenda}
    \vspace{.5cm}
\tableofcontents
\end{frame}

\section{Motion Primitive-Based (Re-)Planning Policy (MP3)}
\begin{frame}{Motion Primitive-Based (Re-)Planning Policy (MP3)}

\center 
    \vspace{1cm}
\includegraphics[width=.7\linewidth]{media/mp3.png}
\begin{itemize}
\item Blackbox and replanning variant
\item Works with sparse, non-markovian rewards
\item Trained on-policy using Trust Region Projection Layers (TRPL)
\end{itemize}
\end{frame}

\begin{frame}{Box Pushing}
\section{Box Pushing}

\begin{columns}[t]
    \begin{column}{0.5\textwidth}
        \begin{itemize}
            \item Goal: Use a ``finger'' to push a box to a target pose
                \begin{itemize}
                    \item Random start pose
                    \item Fixed target pose
                \end{itemize}
        \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
        \begin{itemize}
                \item Challenges
                    \begin{itemize}
                            \item Underactuated system
                            \item Complex table-box interactions
                            \item Complex robot kinematic 
                            \item Trajectories must be safe and executable
                    \end{itemize}
        \end{itemize}
    \end{column}


\end{columns}
\center
    \includegraphics[height=3cm]{media/2dboxpushing.png}
    \vspace{.1cm}\\
    Box Pushing is a challenging benchmark problem for motion primitive reinforcement learning.
\end{frame}

\begin{frame}{Box Pushing}

\begin{columns}[t]
    \begin{column}{0.4\textwidth}
        \vspace{1cm}
        \begin{itemize}
            \item Goal: Use a finger to push a box to a target pose
                \begin{itemize}
                    \item Random start pose
                    \item Fixed target pose
                \end{itemize}
            \item Action space: 2D finger positions
            \item Observation:
                \begin{itemize}
                    \item Finger Position
                    \item Box Quaternion + Position
                \end{itemize}
            \item Success
                \begin{itemize}
                \item $\max_t(v_t) < v_\text{max}$
                \item $\text{err}_{position} \leq 5 \text{cm}$
                \item $\text{err}_{rotation} \leq 0.5 \text{rad}$
                \end{itemize}
        \end{itemize}
            \vspace{1em}
    \end{column}
    \begin{column}{0.5\textwidth}
        \vspace{.5cm}
        \[
        \begin{aligned}
            \text{Reward} &:= \textcolor{kit-blue100}{\text{Final Euclidean Distance}} \\
             &+  \textcolor{kit-blue100}{\text{Final Rotational Distance}} \\
             &+  \textcolor{kit-blue100}{\mathds{1} \left\{\text{success}\right\} } \\
             &+  \textcolor{kit-green100}{\max_t\  \text{step}(v_t)} \\
             &+  \textcolor{kit-lila100}{\sum_t \left\Vert x_t - x_t^\text{clipped} \right\Vert }\\
             \\
    step(v) := & \includegraphics[scale=.4]{media/step.pdf} \\
        \end{aligned}
    \]

    \end{column}
\end{columns}
\center
    Our reward includes \textcolor{kit-blue100}{sparse}, \textcolor{kit-green100}{non-markovian} and \textcolor{kit-lila100}{dense} components.
\end{frame}

\section{Sim2Real}
\begin{frame}{Moving into the real world --- TODO: Better title}
\begin{columns}
    \begin{column}{0.5\textwidth}
        \begin{itemize}
                \item No controller tracks perfectly
                \item The agent will optimize the commanded trajectory based on the \textit{tracked} trajectory.
                \item Therefore \textbf{tuning} for the real robot and \textbf{randomization} are crucial!
                \item This is universal for all real-robot MP applications.
        \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
\includegraphics[width=\linewidth]{media/traj_error.pdf}
    \end{column}
\end{columns}

\end{frame}
\section{Sim2Real}
\begin{frame}{Moving into the real world --- TODO: Better title}
\begin{columns}
    \begin{column}{0.5\textwidth}
        \begin{itemize}
                \item Our approach:
                    \begin{itemize}
                            \item Record real-robot executions
                            \item Optimize PD parameters using bayesian optimization
                            \item Choose a lower/higher P-gain
                            \item Randomize between them during training
                    \end{itemize}
        \end{itemize}
    \end{column}

    \begin{column}{0.5\textwidth}
\includegraphics[width=\linewidth]{media/ctrl_error.pdf}\\
    \end{column}
\end{columns}

\end{frame}

\section{Lab Setup}
\begin{frame}{Box Pushing --- Lab Setup}
    \begin{columns}
    \begin{column}{0.45\textwidth}
    \vspace{1cm}
\includegraphics[width=\linewidth]{media/Architecture.pdf}

    \end{column}
    \begin{column}{0.35\textwidth}
    \vspace{1cm}
\includegraphics[width=\linewidth]{media/labsetup2.jpg}

    \end{column}
    \end{columns}

\end{frame}

\section{Results}
\begin{frame}{Results}
\center
    \includegraphics[width=.7\linewidth]{media/blackbox_presentation.pdf}\\
    \includegraphics[width=.7\linewidth]{media/replan_presentation.pdf}
\end{frame}

\begin{frame}{Further Work}

    TODO: Image of sweeps.pdf

    Main points here: 
    \begin{itemize}
            \item get better performance
            \item properly investigate the importance of DR/replanning/sparse rewards/markovian rewards
            \item compare with dense policies
    \end{itemize}


    
\end{frame}


\appendix
\beginbackup{}
\backupend{}

\end{document}
